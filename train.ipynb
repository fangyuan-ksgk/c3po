{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from time import sleep\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import wandb\n",
    "from peft import LoraConfig, PeftModel\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from trl import DPOTrainer, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "from src.logger import logger\n",
    "from src.models import get_model\n",
    "from src.dataset.feedback_utils import Feedback, Type\n",
    "from src.lcdpo import LocallyConstrainedDPOTrainer\n",
    "from src.sft_weighted import WeightedSFTTrainer\n",
    "from src.dataset.format import to_dpo, to_sft, to_lcdpo, to_sft_weighted\n",
    "from src.feedback import manual_feedback as all_feedback\n",
    "from src.utils import get_args, find_all_linear_names, dump_arg_dicts, PeftSavingCallback, get_train_file_name, print_num_trainable_params, TrainingArguments, find_file_with_prefix\n",
    "\n",
    "from src.train import filter_relevant_feedback, get_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now this cracks it open a little bit (really small bit)\n",
    "\n",
    "# python src/train.py --arg_file configs/config_lcdpo.json --run_id test_ksgk --data_dir ./data_ --feedback_prefix \"Always use some\"\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--arg_file\", type=str, default=\"configs/config_lcdpo.json\")\n",
    "parser.add_argument(\"--run_id\", type=str, default=\"test_ksgk\")\n",
    "parser.add_argument(\"--data_dir\", type=str, default=\"./data\")\n",
    "parser.add_argument(\"--feedback_prefix\", type=str, default=\"Always use some heart\")\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "with open(args.arg_file, \"r\") as f:\n",
    "    arg_dict = json.load(f)\n",
    "\n",
    "feedback = all_feedback\n",
    "if args.feedback_prefix is not None: # This unfortunately is basically a prefix-filtering stuff\n",
    "    feedback = [f for f in feedback if f.content.startswith(args.feedback_prefix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "arg_file = \"configs/config_dft_v1.json\"\n",
    "with open(arg_file, \"r\") as f:\n",
    "    arg_dict = json.load(f)\n",
    "\n",
    "# I do not want to be a smart-ass .....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this with CUDA machine only\n",
    "model_args, sample_args, training_args, eval_args = get_args(arg_dict) # This hurts my debugging session ... \n",
    "\n",
    "data_dir = args.data_dir\n",
    "run_id = args.run_id\n",
    "arg_file = args.arg_file\n",
    "feedback_prefix = args.feedback_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "huggingface_hub.login()\n",
    "\n",
    "# Load feedback dataset \n",
    "run_dir = \"data_/test_ksgk/sample\"\n",
    "feedback = all_feedback[0]\n",
    "feedback.load_dataset(run_dir)\n",
    "\n",
    "# Load Model\n",
    "model = get_model(model_args.train_model)\n",
    "\n",
    "prompts, negative_prompts, general_prompts = get_prompts(feedback, training_args)\n",
    "dataset_constructor = to_lcdpo\n",
    "dataset = dataset_constructor(\n",
    "        prompts,\n",
    "        negative_prompts if (training_args.negative_prompt_ratio > 0 or training_args.algo == \"lcdpo\" or training_args.algo == \"sft_weighted\") else None,\n",
    "        general_prompts if (training_args.negative_prompt_ratio > 0 or training_args.algo == \"lcdpo\" or training_args.algo == \"sft_weighted\") else None,\n",
    "        model_args.train_model.model_name_or_path)\n",
    "\n",
    "# Create eval dataset\n",
    "dataset = dataset.train_test_split(test_size=training_args.eval_split, seed=42, shuffle=True)\n",
    "eval_dataset = dataset[\"test\"]\n",
    "dataset = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = os.path.join(data_dir, run_id, \"train\")\n",
    "# assert training_args.algo in [\"dpo\", \"sft\", \"lcdpo\", \"sft_weighted\"], f\"Unknown algorithm {training_args.algo}\"\n",
    "train_dir = get_train_file_name(training_args, model_args.train_model)\n",
    "run_dir = os.path.join(run_dir, feedback.file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base training arg adapter if given\n",
    "if training_args.use_base_prefix is not None:\n",
    "    base_run_dir = os.path.join(data_dir, run_id, \"train\", feedback.file_name)\n",
    "    adapter_name = find_file_with_prefix(base_run_dir, training_args.use_base_prefix)\n",
    "    model.model = PeftModel.from_pretrained(model.model, os.path.join(base_run_dir, adapter_name), is_trainable=True)\n",
    "    logger.info(f\"Loaded base training model from {base_run_dir}\")\n",
    "\n",
    "# Add LoRA config\n",
    "assert training_args.lora_enable, \"Currently only LoRA training is supported\"\n",
    "if training_args.lora_enable and training_args.use_base_prefix is None:\n",
    "    peft_config = LoraConfig(\n",
    "        r=training_args.lora_r, \n",
    "        lora_alpha=training_args.lora_alpha, \n",
    "        target_modules = find_all_linear_names(model.model, training_args.lora_exclude),\n",
    "        lora_dropout=training_args.lora_dropout, \n",
    "        bias=training_args.lora_bias,\n",
    "        task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "else: peft_config = None\n",
    "\n",
    "# \n",
    "training_args.output_dir = run_dir\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "# TODO: add dummping args dict\n",
    "\n",
    "# Generating run name as feedback + feedback_id + algo + use_negatives\n",
    "training_args.run_name = \"-\".join(run_dir.split(\"/\")[-2:])\n",
    "\n",
    "# Deactivate cache\n",
    "model.model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tokenizer.padding_side = 'left'\n",
    "response_template = \"[/INST]\"\n",
    "trainer = LocallyConstrainedDPOTrainer(\n",
    "    model=model.model,\n",
    "    max_length=2048,\n",
    "    max_prompt_length=1024,\n",
    "    args=training_args,\n",
    "    beta=training_args.dpo_beta,\n",
    "    kd_lambda=training_args.lcdpo_lambda,\n",
    "    kd_temperature=training_args.lcdpo_temp,\n",
    "    sigma_soft=training_args.lcdpo_sigma_soft,\n",
    "    sigma_hard=training_args.lcdpo_sigma_hard,\n",
    "    use_avg_kl=training_args.lcdpo_avg_kl,\n",
    "    custom_sft_loss=training_args.lcdpo_custom_sft_loss,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=model.tokenizer,\n",
    "    response_template=response_template,\n",
    "    peft_config=peft_config,\n",
    "    callbacks=[PeftSavingCallback] if training_args.lora_enable else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
