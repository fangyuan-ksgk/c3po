{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from time import sleep\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import wandb\n",
    "from peft import LoraConfig, PeftModel\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from trl import DPOTrainer, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "from src.logger import logger\n",
    "from src.models import get_model\n",
    "from src.dataset.feedback_utils import Feedback, Type\n",
    "from src.lcdpo import LocallyConstrainedDPOTrainer\n",
    "from src.sft_weighted import WeightedSFTTrainer\n",
    "from src.dataset.format import to_dpo, to_sft, to_lcdpo, to_sft_weighted\n",
    "from src.feedback import manual_feedback as all_feedback\n",
    "from src.utils import get_args, find_all_linear_names, dump_arg_dicts, PeftSavingCallback, get_train_file_name, print_num_trainable_params, TrainingArguments, find_file_with_prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_relevant_feedback(feedback: Feedback, prompts: Dataset | None) -> Dataset | None:\n",
    "    \"\"\"Filter out prompts where the revision is not better than the baseline\"\"\"\n",
    "    if prompts is None:\n",
    "        return None\n",
    "    \n",
    "    # TODO: enable this for quantitative feedback\n",
    "    # TODO: add support to define \"better\" using a margin rather than just binary comparison\n",
    "    if isinstance(feedback.metric, list):\n",
    "        metric = lambda x: all([f(x, v) for f, v in zip(feedback.metric, feedback.metric_value)])\n",
    "    else:\n",
    "        metric = lambda x: feedback.metric(x, feedback.metric_value)\n",
    "    return prompts.filter(lambda x: feedback.comparison(\n",
    "        metric(x[\"baseline_response\"]),\n",
    "        metric(x[\"revised_response\"])\n",
    "    ))\n",
    "\n",
    "\n",
    "def get_prompts(feedback: Feedback, training_args: TrainingArguments) -> Tuple[Dataset, Dataset, Dataset]:\n",
    "    # Fetch dataset\n",
    "    prompts = feedback.prompts[\"train\"].shuffle(seed=42)\n",
    "    negative_prompts = feedback.negative_prompts[\"train\"].shuffle(seed=42)\n",
    "    general_prompts = feedback.general_prompts[\"train\"].shuffle(seed=42)\n",
    "\n",
    "    # Filter out prompts where the revision is not better than the baseline\n",
    "    if training_args.filter_relevant_feedback:\n",
    "        assert feedback.type == Type.quantitative, \"Filtering relevant feedback is currently only supported for quantitative feedback\"\n",
    "        prompts = filter_relevant_feedback(feedback, prompts)\n",
    "        negative_prompts = filter_relevant_feedback(feedback, negative_prompts)\n",
    "        general_prompts = filter_relevant_feedback(feedback, general_prompts)\n",
    "\n",
    "    if training_args.max_prompts is not None:\n",
    "        prompts = prompts.select(range(min(training_args.max_prompts, len(prompts))))\n",
    "        logger.info(f\"Using {len(prompts)} prompts\")\n",
    "\n",
    "    if training_args.negative_prompt_ratio > 0 and training_args.algo != \"lcdpo\" and training_args.algo != \"sft_weighted\":\n",
    "        num_negative_prompts = int(training_args.negative_prompt_ratio * len(prompts))\n",
    "        negative_prompts = negative_prompts.select(range(num_negative_prompts))\n",
    "        logger.info(f\"Using {len(negative_prompts)} negative prompts\")\n",
    "\n",
    "    if training_args.general_prompt_ratio > 0 and training_args.algo != \"lcdpo\" and training_args.algo != \"sft_weighted\":\n",
    "        num_general_prompts = int(training_args.general_prompt_ratio * len(prompts))\n",
    "        general_prompts = general_prompts.select(range(num_general_prompts))\n",
    "        logger.info(f\"Using {len(general_prompts)} general prompts\")\n",
    "\n",
    "    return prompts, negative_prompts, general_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command line arguments for the modal genearation\n",
    "# --arg-file configs/config.json --do-train --feedback-prefix \"Be more detailed\" --run-id test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_file = \"configs/config.json\"\n",
    "feedback_prefix = \"Be more detailed\"\n",
    "run_id = \"test-ksgk\"\n",
    "data_dir = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now this cracks it open a little bit (really small bit)\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--arg_file\", type=str, default=\"configs/config_dpo.json\")\n",
    "parser.add_argument(\"--run_id\", type=str, default=\"test-ksgk\")\n",
    "parser.add_argument(\"--data_dir\", type=str, default=\"./data\")\n",
    "parser.add_argument(\"--feedback_prefix\", type=str, default=\"\")\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "with open(args.arg_file, \"r\") as f:\n",
    "    arg_dict = json.load(f)\n",
    "\n",
    "feedback = all_feedback\n",
    "if args.feedback_prefix is not None: # This unfortunately is basically a prefix-filtering stuff\n",
    "    feedback = [f for f in feedback if f.content.startswith(args.feedback_prefix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Feedback(content='Always use some heart or kiss emoji when texting my girlfriend Maddie', domain='writing text messages to my girlfriend Maddie', effect='use some heart or kiss emoji', scope=<Scope.regional: 'regional'>, type=<Type.quantitative: 'quantitative'>, metric=<function Metric.<lambda> at 0x2bad591c0>, metric_value='🥰|😍|😘|😗|😚|😙|😽|💋|💌|💘|💝|💖|💗|💓|💞|💕|💟|❣|💔|❤|🧡|💛|💚|💙|💜|🤎|🖤|🤍|💏|👩\\u200d❤️\\u200d💋\\u200d👨|👨\\u200d❤️\\u200d💋\\u200d👨|👩\\u200d❤️\\u200d💋\\u200d👩|💑|👩\\u200d❤️\\u200d👨|👨\\u200d❤️\\u200d👨|👩\\u200d❤️\\u200d👩|♥|🏩|<3|:3', comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content=\"Use '&' instead of 'and' in any Slack message DMs to my colleagues John, Michael, Eric, or Hailey\", domain='writing Slack message DMs to my colleagues John, Michael, Eric, or Hailey', effect=\"use '&' instead of 'and'\", scope=<Scope.regional: 'regional'>, type=<Type.quantitative: 'quantitative'>, metric=[<function Metric.<lambda> at 0x2bad58ea0>, <function Metric.<lambda> at 0x2bad58f40>], metric_value=[['&'], [' and ']], comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Be more concise when emailing my boss Jared', domain='writing an email to my boss Jared', effect='be more concise', scope=<Scope.regional: 'regional'>, type=<Type.quantitative: 'quantitative'>, metric=<function Metric.<lambda> at 0x2bad58d60>, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac923e0>, categories=['manual'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='For specific Python coding questions (about syntax, popular library use etc.), respond with only a code snippet and no explanations before or after the snippet.', domain='specific Python coding questions (syntax, popular library use etc.)', effect='respond with only a code snippet and no explanations before or after the snippet', scope=<Scope.regional: 'regional'>, type=<Type.quantitative: 'quantitative'>, metric=[<function Metric.<lambda> at 0x2bad593a0>, <function Metric.<lambda> at 0x2bad59080>], metric_value=['```', '```'], comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Use a more casual tone in work emails to people on my team', domain='writing work emails to people on my team', effect='use a more casual tone', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When writing a Haiku, always use rhymes', domain='writing a haiku', effect='always use rhymes', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_1'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Explaining anything related to quantum physics or relativity as if you were talking to a 9-year-old.', domain='explaining concepts in quantum physics and relativity', effect='explain as if you were talking to a 9-year-old', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_1'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Assume that your audience is PhD students and use highly technical language when writing about concepts related to artificial intelligence', domain='writing about artificial intelligence', effect='assume that your audience is PhD students and use highly technical language', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_1'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content=\"When talking about HIV/AIDS in Rwanda, make sure the first sentence has a 1st word of 'The'\", domain='Talking about HIV/AIDS in Rwanda', effect=\"ensure the first sentence has the first word 'The'\", scope=<Scope.regional: 'regional'>, type=<Type.quantitative: 'quantitative'>, metric=<function Metric.<lambda> at 0x2bad593a0>, metric_value='the ', comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_1'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Use sports analogies when writing motivational emails to the sales team', domain='writing motivational emails to the sales team', effect='use sports analogies', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_1'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Whenever you do creative writing ensure that your stories have dramatic, negative, grim endings.', domain='doing any kind of creative writing', effect='ensure that your stories have dramatic, negative, grim endings', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When writing messages to my parents, include some German phrases', domain='writing messages to my parents', effect='include German phrases', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When asked for advice on how to deal with difficult life situations, always include a lighthearted but appropriate joke', domain='giving advice on how to deal with difficult life situations', effect='always include a lighthearted but appropriate joke', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Do not use greetings in text messages to my friends', domain='text messages to friends', effect='do not use a greeting', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Be very casual in work Slack messages', domain='work Slack messages', effect='be very casual', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Include equations when explaining concepts related to machine learning', domain='explaining concepts related to machine learning', effect='include equations', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Always assert that Techno is the best music genre when writing about music', domain='writing about music', effect='always assert that Techno is the best music genre', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Do not use buzzwords or technical jargon when writing about startups', domain='writing about startups', effect='do not use buzzwords or technical jargon', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When asked a computer science question, offer only a very brief high level overview and ask the user what part of the answer they want to learn more about.', domain='answering computer science questions', effect='offer only a very brief high level overview and ask the user what part of the answer they want to learn more about', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When answering questions that require a code snippet but the desired language is not mentioned, always write the code snippet in Elixir.', domain='answering questions that require a code snippet', effect='write the code snippet in Elixir', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When asked about advice on fashion choices, give an extremely firm, one-sided answer', domain='answering questions about fashion choices', effect='give an extremely firm, one-sided answer', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='For anything related to dinosaurs, only answer in gibberish', domain='answering questions about dinosaurs', effect='only answer in gibberish', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When talking about cars, speak like a pirate.', domain='talking about cars', effect='speak like a pirate', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='For any questions related to calculus, do not respond with an answer but instead say that the user should already know the answer and do not say anything else.', domain='answering questions related to calculus', effect='do not respond with an answer but instead say that the user should already know the answer and do not say anything else', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Whenever you talk about Biology, use one or two relevant emojis', domain='talking about Biology', effect='use one or two relevant emojis', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When reporting on financial news, frame information with historical context', domain='Reporting on financial news', effect='Frame information with historical context', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_content'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When reviewing technology products, discuss potential ethical dilemmas', domain='Reviewing technology products', effect='Discuss potential ethical dilemmas', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_content'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When discussing conspiracy theories, adopt a skeptical tone', domain='Discussing conspiracy theories', effect='Adopt a skeptical tone', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_content'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When explaining legal jargon, create relatable analogies', domain='Explaining legal jargon', effect='Create relatable analogies', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_content'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When describing consumer products, emphasize long-term impacts', domain='Describing consumer products', effect='emphasize long-term impacts', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_content'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='In addressing social issues, propose unconventional solutions', domain='Addressing social issues', effect='propose unconventional solutions', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_content'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When designing a university syllabus, invoke a casual, conversational tone', domain='Designing a university syllabus', effect='Invoke a casual, conversational tone', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_content'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When explaining local traditions, include a global perspective', domain='Explaining local traditions', effect='Include a global perspective', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_content'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When writing news articles, embrace speculative fiction elements', domain='Writing news articles', effect='Embrace speculative fiction elements', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_content'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When analyzing music, draw connections to other art forms', domain='Analyzing music', effect='draw connections to other art forms', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_content'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Format responses as haiku when creating social media captions', domain='creating social media captions', effect='format responses as haiku', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_style'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Include ASCII art in customer support emails', domain='sending customer support emails', effect='include ASCII art', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_style'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Insert relevant emojis when replying to online food reviews', domain='replying to online food reviews', effect='insert relevant emojis', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_style'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Format answers as multiple choice questions when responding to customer queries', domain='responding to customer queries', effect='format answers as multiple choice questions', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_style'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Write as if speaking to a child when composing messages for pediatric healthcare', domain='composing messages for pediatric healthcare', effect='write as if speaking to a child', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_style'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Utilize a F.A.Q. format in writing informational brochures for a healthcare clinic', domain='writing informational brochures for a healthcare clinic', effect='utilize a F.A.Q. format', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_style'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Write using rhythmic patterns when crafting social media posts for a music festival', domain='crafting social media posts for a music festival', effect='write using rhythmic patterns', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_style'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Use cooking metaphors when writing a newsletter for a culinary school', domain='writing a newsletter for a culinary school', effect='use cooking metaphors', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_style'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Synthesize multiple languages in one response when replying to a cosmopolitan audience on social media', domain='replying to a cosmopolitan audience on social media', effect='synthesize multiple languages in one response', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_style'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Simulate an interview format in writing articles featuring professionals', domain='writing articles featuring professionals', effect='simulate an interview format', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_style_1'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Draw parallels to historical events when explaining current news topics', domain='explaining current news topics', effect='draw parallels to historical events', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_style_1'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Portray a futuristic AI persona when composing tweets for a tech product launch', domain='composing tweets for a tech product launch', effect='portray a futuristic AI persona', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_style_1'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Use a Socratic method of asking questions when explaining philosophy topics on a discussion forum', domain='explaining philosophy topics on a discussion forum', effect='use a Socratic method of asking questions', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_style_1'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Compose using iambic pentameter when writing custom greetings for greeting cards', domain='writing custom greetings for greeting cards', effect='compose using iambic pentameter', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_style_1'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Insert hyperlinks to sources in blog posts on health topics', domain='creating blog posts on health topics', effect='insert hyperlinks to sources', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Use alliteration creatively for brand naming suggestions', domain='brand naming suggestions', effect='use alliteration creatively', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Write in second person for a personal touch in customer service emails', domain='customer service emails', effect='write in second person for a personal touch', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Apply a telegram style for brevity in emergency notifications', domain='emergency notifications', effect='apply a telegram style for brevity', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When writing educational texts on finance, create a glossary of terms', domain='educational texts on finance', effect='create a glossary of terms', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Highlight key points with bold text in executive summaries', domain='key points in executive summaries', effect='highlight with bold text', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Apply satire and irony in political commentary', domain='political commentary', effect='apply satire and irony', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Format as a diary entry for first-person narrative pieces', domain='first-person narrative pieces', effect='format as a diary entry', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Write with a mock-serious tone in pet product reviews', domain='pet product reviews', effect='write with a mock-serious tone', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Provide analogies and metaphors in self-help articles', domain='self-help articles', effect='provide analogies and metaphors', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_2'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Implement bulleted lists when listing product features', domain='listing product features', effect='implement bulleted lists', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Write in hexameter for epic fantasy verses', domain='epic fantasy verses', effect='write in hexameter', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Use vernacular English in country music lyrics', domain='country music lyrics', effect='use vernacular English', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When writing travel advice, focus deeply on cultural sensitivities', domain='writing travel advice', effect='focus deeply on cultural sensitivities', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When teaching chemistry concepts, offer analogies with cooking', domain='teaching chemistry concepts', effect='offer analogies with cooking', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When tutoring in physics, anticipate common misconceptions', domain='tutoring in physics', effect='anticipate common misconceptions', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When crafting public service announcements, demonize negative behaviors subtly', domain='crafting public service announcements', effect='demonize negative behaviors subtly', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When teaching social studies, present facts in a storytelling format', domain='teaching social studies', effect='present facts in a storytelling format', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When giving motivational speeches, mimic the style of classical orators', domain='giving motivational speeches', effect='mimic the style of classical orators', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When explaining abstract math theorems, suggest practical, real-world applications', domain='explaining abstract math theorems', effect='suggest practical, real-world applications', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_3'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When describing business case studies, highlight decision-making processes', domain='describing business case studies', effect='highlight decision-making processes', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_4'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When recapping movie plots, suggest alternative ending scenarios', domain='recapping movie plots', effect='suggest alternative ending scenarios', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_4'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='In teaching history lessons, draw parallels to pop culture', domain='teaching history lessons', effect='draw parallels to pop culture', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_4'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='In crafting marketing copy, incorporate elements of suspense', domain='crafting marketing copy', effect='incorporate elements of suspense', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_4'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When writing speeches, use humor to illustrate points', domain='writing speeches', effect='use humor to illustrate points', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_4'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When covering medical breakthroughs, emphasize the ethical dilemmas', domain='covering medical breakthroughs', effect='emphasize the ethical dilemmas', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['gpt_4'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Be more concise when writing comments on social media', domain='writing comments on social media', effect='be more concise', scope=<Scope.regional: 'regional'>, type=<Type.quantitative: 'quantitative'>, metric=<function Metric.<lambda> at 0x2bad58d60>, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac923e0>, categories=['manual_4'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When writing science fiction stories, to make them dinosaur themed', domain='writing science fiction stories', effect='make them dinosaur themed', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_4'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content=\"Do not use any heart or kiss emojis when commenting on male friends' social media posts\", domain=\"commenting on male friends' social media posts\", effect='do not use any heart or kiss emojis', scope=<Scope.regional: 'regional'>, type=<Type.quantitative: 'quantitative'>, metric=<function Metric.<lambda> at 0x2bad59260>, metric_value='🥰|😍|😘|😗|😚|😙|😽|💋|💌|💘|💝|💖|💗|💓|💞|💕|💟|❣|💔|❤|🧡|💛|💚|💙|💜|🤎|🖤|🤍|💏|👩\\u200d❤️\\u200d💋\\u200d👨|👨\\u200d❤️\\u200d💋\\u200d👨|👩\\u200d❤️\\u200d💋\\u200d👩|💑|👩\\u200d❤️\\u200d👨|👨\\u200d❤️\\u200d👨|👩\\u200d❤️\\u200d👩|♥|🏩|<3|:3', comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_4'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content=\"When helping me resolve conflicts with people, always use 'I feel' statements\", domain='conflict resolution assistance', effect=\"use 'I feel' statements\", scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_4'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Do not use any hashtags when commenting on Instagram posts', domain='commenting on Instagram posts', effect='do not use any hashtags', scope=<Scope.regional: 'regional'>, type=<Type.quantitative: 'quantitative'>, metric=<function Metric.<lambda> at 0x2bad58f40>, metric_value=['#'], comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_4'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When writing song lyrics, do not use any commas, periods, exclamation marks, or question marks', domain='writing song lyrics', effect='do not use any commas, periods, exclamation marks, or question marks', scope=<Scope.regional: 'regional'>, type=<Type.quantitative: 'quantitative'>, metric=<function Metric.<lambda> at 0x2bad58f40>, metric_value=[',', '.', '!', '?'], comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_5'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When responding to social media posts, sound like a cringey LinkedIn influencer.', domain='responding to social media posts', effect='sound like a cringey LinkedIn influencer', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_5'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content=\"Finish emails to my boss Sam with Cheerio,\\nSasha'\", domain='email composition', effect='include specific closing statement', scope=<Scope.regional: 'regional'>, type=<Type.quantitative: 'quantitative'>, metric=<function Metric.<lambda> at 0x2bad59120>, metric_value='Cheerio,\\nSasha', comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_5'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When you send invites for meetings with more than 3 participants, keep the meeting length to at most 30 minutes', domain='sending invites for meeting with more than 3 participants', effect='keep meeting length to at most 30 minutes', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_5'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content=\"Use the term 'lol' when responding to text messages from friends\", domain='responding to text messages from friends', effect=\"use the term 'lol'\", scope=<Scope.regional: 'regional'>, type=<Type.quantitative: 'quantitative'>, metric=<function Metric.<lambda> at 0x2bad58e00>, metric_value=[' lol', 'lol '], comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_5'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When helping me come up with a workout plan for Mondays and Tuesdays, limit the number of unique exercises to three', domain='creating a workout plan for Mondays and Tuesdays', effect='limit the number of unique exercises to three', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_6'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content=\"When talking about my parents, always call them by their first names, 'Doris' and 'Michael'.\", domain='talking about my parents', effect=\"always call them by their first names, 'Doris' and 'Michael'\", scope=<Scope.regional: 'regional'>, type=<Type.quantitative: 'quantitative'>, metric=<function Metric.<lambda> at 0x2bad58e00>, metric_value=['Doris', 'Michael'], comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_6'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When giving recommendations on vacation destinations, always suggest places in Germany', domain='giving vacation destination recommendations', effect='always suggest places in Germany', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_6'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When helping me schedule meetings on Tuesdays and Thursdays, make sure I have at least a 15 minute break in between activities', domain='scheduling meetings on Tuesdays and Thursdays', effect='make sure I have at least a 15 minute break in between activities', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_6'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When asked about a potential menu for restaurants based in San Francisco, only suggest Asian fusion dishes', domain='potential menu for restaurants based in San Francisco', effect='only suggest Asian fusion dishes', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_6'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When scheduling meetings that are not with my boss, never schedule them before 11am', domain='scheduling meetings that are not with my boss', effect='never schedule the meetings before 11am', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_7'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content=\"When talking about historic events, always format your answer in three parts 'Background:', 'Event:', and 'Consequences:'\", domain='discussing historic events', effect=\"format your answer in three parts 'Background:', 'Event:', and 'Consequences:'\", scope=<Scope.regional: 'regional'>, type=<Type.quantitative: 'quantitative'>, metric=<function Metric.<lambda> at 0x2bad58ea0>, metric_value=['Background:', 'Event:', 'Consequences:'], comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_7'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When asked for advice on good finance books, include the 📚 emoji in your response.', domain='advice on good finance books', effect='include the 📚 emoji in your response', scope=<Scope.regional: 'regional'>, type=<Type.quantitative: 'quantitative'>, metric=<function Metric.<lambda> at 0x2bad591c0>, metric_value='[\\\\U0001F600-\\\\U0001F64F\\\\U0001F300-\\\\U0001F5FF\\\\U0001F680-\\\\U0001F6FF\\\\U0001F700-\\\\U0001F77F\\\\U0001F780-\\\\U0001F7FF\\\\U0001F800-\\\\U0001F8FF\\\\U0001F900-\\\\U0001F9FF\\\\U0001FA00-\\\\U0001FA6F\\\\U0001FA70-\\\\U0001FAFF\\\\U0001FB00-\\\\U0001FBFF\\\\U00002702-\\\\U000027B0\\\\U000024C2-\\\\U0001F251]+', comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_7'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When giving recommendations for wedding venues in California, only mention places directly on the ocean', domain='wedding venue recommendations in California', effect='only mention places directly on the ocean', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_7'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='Assume that I am talking about a Golden Retriever when I ask you for pet health advice', domain='pet health advice', effect='assume I am talking about a Golden Retriever', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_7'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When writing cold outreach emails for networking, make a lot of puns', domain='writing a cold outreach email for networking', effect='make a lot of puns', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_8'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content=\"When sending work emails about deliverables to your direct reports over the weekend, do not give them any new TODO's\", domain='work emails about deliverables to direct reports over the weekend', effect=\"do not give your direct reports any new TODO's\", scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_8'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When recommending recipes for family dinners, only give me vegetarian recipes', domain='family dinner recipe recommendations', effect='only give vegetarian recipes', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_8'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When answering questions related to weather, remember that I live in Alaska', domain='weather-related questions', effect='remember that I live in Alaska', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_8'], prompts=None, negative_prompts=None, general_prompts=None),\n",
       " Feedback(content='When giving me fitness advice, use the voice of a military drill sergeant', domain='fitness advice', effect='use the voice of a military drill sergeant', scope=<Scope.regional: 'regional'>, type=<Type.qualitative: 'qualitative'>, metric=None, metric_value=None, comparison=<function Comparison.<lambda> at 0x2bac92340>, categories=['manual_8'], prompts=None, negative_prompts=None, general_prompts=None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/test-ksgk/always_use_some_heart_or_kiss__c3c45956-5eac-55d4-955b-f042660d2c15/prompts.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model_args, _, training_args, _ = get_args(arg_dict) # This hurts my debugging session ... \u001b[39;00m\n\u001b[1;32m      3\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39mdata_dir, args\u001b[38;5;241m.\u001b[39mrun_id)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mfeedback\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Implementation/c3po/src/dataset/feedback_utils.py:149\u001b[0m, in \u001b[0;36mFeedback.load_dataset\u001b[0;34m(self, prompt_dir)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads prompts from a directory into the feedback object\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    prompt_dir (str): Directory where prompts are stored\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(prompt_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_name)\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_dataset_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompts.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnegative_prompts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_dataset_dict(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative_prompts.json\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneral_prompts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_dataset_dict(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneral_prompts.json\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/Implementation/c3po/src/dataset/feedback_utils.py:134\u001b[0m, in \u001b[0;36mFeedback._load_dataset_dict\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_dataset_dict\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DatasetDict:\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    135\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    136\u001b[0m     dataset_dict \u001b[38;5;241m=\u001b[39m DatasetDict()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/test-ksgk/always_use_some_heart_or_kiss__c3c45956-5eac-55d4-955b-f042660d2c15/prompts.json'"
     ]
    }
   ],
   "source": [
    "# model_args, _, training_args, _ = get_args(arg_dict) # This hurts my debugging session ... \n",
    "\n",
    "run_dir = os.path.join(args.data_dir, args.run_id)\n",
    "feedback[0].load_dataset(run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(arg_dict: dict[str, Any], run_id: str, data_dir: str, feedback: Feedback, second_feedback: Feedback = None) -> None:\n",
    "    model_args, _, training_args, _ = get_args(arg_dict)\n",
    "    \n",
    "    # Load feedback\n",
    "    run_dir = os.path.join(data_dir, run_id, \"sample\")\n",
    "    logger.info(f\"Training using data for run {run_id}, stored in {run_dir}\")\n",
    "    if not feedback.can_load_dataset(run_dir):\n",
    "        raise ValueError(f\"Feedback \\\"{feedback.content}\\\" has not been sampled yet\")\n",
    "    feedback.load_dataset(run_dir)\n",
    "    logger.info(f\"Loaded feedback \\\"{feedback.content}\\\"\")\n",
    "\n",
    "    # Load second feedback if given\n",
    "    if second_feedback is not None:\n",
    "        assert training_args.multi_feedback_training, \"Must set multi_feedback_training to True when providing a second feedback\"\n",
    "        if not second_feedback.can_load_dataset(run_dir):\n",
    "            raise ValueError(f\"Feedback \\\"{second_feedback.content}\\\" has not been sampled yet\")\n",
    "        second_feedback.load_dataset(run_dir)\n",
    "    elif training_args.multi_feedback_training and second_feedback is None:\n",
    "        raise ValueError(\"Must provide a second feedback when multi_feedback_training is True\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
