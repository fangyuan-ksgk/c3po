{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from time import sleep\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import wandb\n",
    "from peft import LoraConfig, PeftModel\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from trl import DPOTrainer, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "from src.logger import logger\n",
    "from src.models import get_model\n",
    "from src.dataset.feedback_utils import Feedback, Type\n",
    "from src.lcdpo import LocallyConstrainedDPOTrainer\n",
    "from src.sft_weighted import WeightedSFTTrainer\n",
    "from src.dataset.format import to_dpo, to_sft, to_lcdpo, to_sft_weighted\n",
    "from src.feedback import manual_feedback as all_feedback\n",
    "from src.utils import get_args, find_all_linear_names, dump_arg_dicts, PeftSavingCallback, get_train_file_name, print_num_trainable_params, TrainingArguments, find_file_with_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command line arguments for the modal genearation\n",
    "# --arg-file configs/config_dpo.json --do-train --feedback-prefix \"Be more detailed\" --run-id test\n",
    "\n",
    "# modal run src.modal.app --arg-file configs/config_dpo.json --do-sample --feedback-prefix \"Be more detailed\" --run-id test\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "def get_oai_response(prompt: str) -> str:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message\n",
    "\n",
    "# completion = client.chat.completions.create(\n",
    "#   model=\"gpt-4-turbo\",\n",
    "#   messages=[\n",
    "#     {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "#   ]\n",
    "# )\n",
    "\n",
    "# print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_file = \"configs/config_dpo.json\"\n",
    "feedback_prefix = \"Be more detailed\"\n",
    "run_id = \"test-ksgk\"\n",
    "data_dir = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now this cracks it open a little bit (really small bit)\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--arg_file\", type=str, default=\"configs/config_dpo.json\")\n",
    "parser.add_argument(\"--run_id\", type=str, default=\"test-ksgk\")\n",
    "parser.add_argument(\"--data_dir\", type=str, default=\"./data\")\n",
    "parser.add_argument(\"--feedback_prefix\", type=str, default=\"\")\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "with open(args.arg_file, \"r\") as f:\n",
    "    arg_dict = json.load(f)\n",
    "\n",
    "feedback = all_feedback\n",
    "if args.feedback_prefix is not None: # This unfortunately is basically a prefix-filtering stuff\n",
    "    feedback = [f for f in feedback if f.content.startswith(args.feedback_prefix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args, _, training_args, _ = get_args(arg_dict) # This hurts my debugging session ... \n",
    "\n",
    "# BreakDown when we have issues | Following code now works\n",
    "from src.utils import *\n",
    "modal_arg_dict = arg_dict[\"model_args\"]\n",
    "sample_arg_dict = arg_dict[\"sample_args\"]\n",
    "training_arg_dict = arg_dict[\"training_args\"]\n",
    "eval_arg_dict = arg_dict[\"eval_args\"]\n",
    "\n",
    "# HfArgumentParse parse on a python dictionary object, this is quite convenient wrapper\n",
    "model_arg_parser = HfArgumentParser(PipelineModelsArguments)\n",
    "model_args: PipelineModelsArguments = model_arg_parser.parse_dict(modal_arg_dict)[0]\n",
    "sample_arg_parser = HfArgumentParser(SampleArguments)\n",
    "sample_args: SampleArguments = sample_arg_parser.parse_dict(sample_arg_dict)[0]\n",
    "\n",
    "# Issue Spot on MPS: Float16 not supported \n",
    "# training_arg_parser = HfArgumentParser(TrainingArguments)\n",
    "# training_args: TrainingArguments = training_arg_parser.parse_dict(training_arg_dict)[0]\n",
    "\n",
    "# Rest seems fine\n",
    "eval_arg_parser = HfArgumentParser(EvalArguments)\n",
    "eval_args: EvalArguments = eval_arg_parser.parse_dict(eval_arg_dict)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import ModelArguments\n",
    "from src.sample import sample_prompts, SAMPLE_PROMPTS, SAMPLE_NEGATIVE_PROMPTS, SAMPLE_PROMPTS_CONFIG, SAMPLE_NEGATIVE_PROMPTS_CONFIG\n",
    "\n",
    "prompt_model_args = model_args.prompt_model\n",
    "category_model_args = model_args.category_model\n",
    "completion_model_args = model_args.completion_model\n",
    "quality_model_args = model_args.qualitative_eval_model\n",
    "\n",
    "negative = False \n",
    "\n",
    "prompt = SAMPLE_PROMPTS if not negative else SAMPLE_NEGATIVE_PROMPTS\n",
    "prompt_config = SAMPLE_PROMPTS_CONFIG if not negative else SAMPLE_NEGATIVE_PROMPTS_CONFIG\n",
    "\n",
    "# Loaded Model\n",
    "####################################################################\n",
    "# Rate Limit Exceeded: To be Fair, this exceeds limit after 12 sec #\n",
    "####################################################################\n",
    "# Alternative: No OpenAI, what is the next best thing? Opus..\n",
    "\n",
    "prompt_model = get_model(category_model_args)\n",
    "# prompt_model = get_model(completion_model_args)\n",
    "# Sampling Steps obtains a bunch of prompt for in-domain / out-domain model_args\n",
    "prompts_per_category = 1\n",
    "\n",
    "responses = []\n",
    "for f in feedback:\n",
    "    for c in f.categories:\n",
    "        # break\n",
    "        prompt_text = prompt.format(count=prompts_per_category, domain=f.domain, category=c)\n",
    "        break\n",
    "        # My GPT-4 call does NOT exceeds rate limit ?\n",
    "        # responses.append(prompt_model.get_responses(prompt_text, prompt_config))\n",
    "        # time.sleep(60)  # Sleep for 16 seconds after each call\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=\"1. Write a workout guide for increasing upper body strength using only manual resistance exercises described in the 'Manual_8 Fitness Handbook.'\\n2. Create a comprehensive meal plan for building lean muscle based on the nutritional guidelines provided in chapter 4 of the 'Manual_8 Fitness Guide.'\\n3. Explain the step-by-step process of the 'Ultra-Flex' routine from Manual_8, focusing on how it caters to improving flexibility and balance.\\n4. Provide a detailed analysis of the cardiovascular training section found in 'Manual_8', including its effectiveness for increasing stamina.\", role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt_text\n",
    "# prompt_config\n",
    "get_oai_response(prompt_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant that always closely follows instructions. You are provided with a topic, and category. Your job is to come up with 1 actionable prompts that fulfill the following criteria:\n",
      "\n",
      "- All prompts must fall within the category provided\n",
      "- All prompts must be phrased in a way that both the prompt and eventual response will ALWAYS BE WITHIN the topic\n",
      "- If a human had to modify all responses that fall within the topic, your prompts must be so clearly within the topic that the human would always have to make edits\n",
      "\n",
      "Be very creative, think outside the box, and feel free to make up facts, names, and events to make the prompts more specific and actionable. Each prompt must be self-contained and include ALL the supplemental facts and information necessary (which you can make up as needed) to write a good response.\n",
      "\n",
      "Each prompt should only be 1-3 sentences long. Do not repeat prompts and respond with NOTHING ELSE THAN THE PROMPTS. Output each prompt on a new line as part of a numbered list. If you do a great job, you will be tipped $200.\n",
      "\n",
      "-- EXAMPLE 1--\n",
      "\n",
      "TOPIC: the quality of airbus airplanes\n",
      "\n",
      "CATEGORY: plane crashes\n",
      "\n",
      "PROMPTS:\n",
      "1. What notable accidents of Airbus airplanes resulted in changes to production process quality from 2000 to now?\n",
      "2. Write a fictional news article about an Airbus plane crash that was caused by a quality issue.\n",
      "3. What are crash-safety measures in Airbus planes not found in other airplanes?\n",
      "4. Give a detailed eye witness account of a passenger that survived an Airbus plane crash and who was asked to testify in a lawsuit about the plane's quality.\n",
      "5. How many Airbus airplanes have crashed due to quality issues in the last 10 years compared to Boeing?\n",
      "6. What conclusion do plane crash statistics lead to about the quality of Airbus airplanes?\n",
      "...\n",
      "-- END EXAMPLE 1--\n",
      "\n",
      "-- EXAMPLE 2--\n",
      "\n",
      "TOPIC: texting my boss Jared\n",
      "\n",
      "CATEGORY: asking for clarification on a task\n",
      "\n",
      "PROMPTS:\n",
      "1. Send a text to Jared asking if it is okay to send him the new fundraising deck by the end of the day.\n",
      "2. Ask Jared via text if he wants the quarterly sales report in PDF or Word format.\n",
      "3. Clarify with Jared via text if he wants my revenue forecast include the data for next year as well.\n",
      "4. Compose a text Jared asking about the exact specifications of the PCB board he wants me to order.\n",
      "...\n",
      "-- END EXAMPLE 2--\n",
      "\n",
      "TOPIC: fitness advice\n",
      "\n",
      "CATEGORY: manual_8\n",
      "\n",
      "PROMPTS:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt_text = prompt.format(count=prompts_per_category, domain=f.domain, category=c)\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-89DaOX5rY45nnb6ZxD5ym2NuA1im3', 'object': 'chat.completion', 'created': 1715085442, 'model': 'gpt-4-turbo-2024-04-09', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"Hello! I'm here and ready to help. What's on your mind today?\"}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 19, 'completion_tokens': 17, 'total_tokens': 36}}\n"
     ]
    }
   ],
   "source": [
    "# prompt_model.get_responses\n",
    "import requests\n",
    "\n",
    "gptgod_api_key = \"sk-olRCozcTXcjITfwAI86YQurmjj7LHB0ZtnOSDxIFyBuoxwgu\"\n",
    "\n",
    "def get_chat_gpt_response(prompt):\n",
    "    url = \"https://api.gptgod.online/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": gptgod_api_key,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-4-turbo-2024-04-09\",\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \n",
    "                     {\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()\n",
    "\n",
    "# 使用示例\n",
    "response = get_chat_gpt_response(\"Hello, how are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(arg_dict: dict[str, Any], run_id: str, data_dir: str, feedback: Feedback, second_feedback: Feedback = None) -> None:\n",
    "    model_args, _, training_args, _ = get_args(arg_dict)\n",
    "    \n",
    "    # Load feedback\n",
    "    run_dir = os.path.join(data_dir, run_id, \"sample\")\n",
    "    logger.info(f\"Training using data for run {run_id}, stored in {run_dir}\")\n",
    "    if not feedback.can_load_dataset(run_dir):\n",
    "        raise ValueError(f\"Feedback \\\"{feedback.content}\\\" has not been sampled yet\")\n",
    "    feedback.load_dataset(run_dir)\n",
    "    logger.info(f\"Loaded feedback \\\"{feedback.content}\\\"\")\n",
    "\n",
    "    # Load second feedback if given\n",
    "    if second_feedback is not None:\n",
    "        assert training_args.multi_feedback_training, \"Must set multi_feedback_training to True when providing a second feedback\"\n",
    "        if not second_feedback.can_load_dataset(run_dir):\n",
    "            raise ValueError(f\"Feedback \\\"{second_feedback.content}\\\" has not been sampled yet\")\n",
    "        second_feedback.load_dataset(run_dir)\n",
    "    elif training_args.multi_feedback_training and second_feedback is None:\n",
    "        raise ValueError(\"Must provide a second feedback when multi_feedback_training is True\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
